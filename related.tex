\section{Related}
\label{sec:related}

\noindent\textbf{Vision Transformers}
Transformers \cite{vaswani2017attention} are born as an architecture to solve sequence-to-sequence problems, handling long-range dependencies in a simple way with the advantage of a strong parallelization compared to state-of-the-art architectures such as RNN and derivatives.
Initially developed for text analysis tasks, transformers have also found application in the image field.
The seminal work \cite{DBLP:conf/iclr/DosovitskiyB0WZ21} first proposed a Vision Transformer (ViT), paving the way for a new generation of detectors, alternative to CNN.
Afterwards, with the aim of improving the performance in terms of accuracy of the results and decreasing the computational need, variants such as the Swin Tranformers \cite{liu2021Swin} were born.
In order to reduce the computational cost of the self-attention mechanism, authors proposed a shifted-windowing scheme to compute self-attention on smaller non-overlapping windows, introducing cross-window connection to cope with the lack of connections between different regions of the image.
As a direct evolution of Swin Tranformers, to process video instead of images, a new architecture was proposed in \cite{liu_video_2022}.
The authors proposed to approximate spatiotemporal self-attention by compute self-attention locally, extending spatial domain to the spatiotemporal domain.

\noindent\textbf{Traffic Anomaly Detection}
To detect anomaly in video, in \cite{hasan2016learning}, authors proposed a convolutional AutoEncoder (ConvAE) trained only on normal frames with the objective of frames reconstruction.
In \cite{luo2017remembering, wang2018abnormal}, authors used Convolutional LSTM Auto-Encoder as framework to encode appearance and motion.
Authors of AnoPred \cite{liu2018future} proposed a multi-task loss which include image intensity, optical flow, gradient, and adversarial losses for video frame-level anomaly detection which apply a UNet to predict a future RGB frame.
In \cite{yao2019unsupervised}, authors proposed an unsupervised method which tracks traffic participants trajectories and detect anomaly monitoring prediction consistency.
In TRN model \cite{xu2019temporal}, authors coupled the action detection task with the future action anticipation during the training.
To predict the action, they use both the historical temporal dependencies modeled by a RNN and the anticipation of the future via a temporal decoder.
In 2020, authors of \cite{9712446} proposed a new dataset of video anomaly detection called Detection of Traffic Anomaly (DoTA).
% TODO check paper https://paperswithcode.com/paper/an-attention-guided-multistream-feature

% Online Action Detection
% Temporal Recurrent Networks for Online Action Detection
% Long Short-Term Transformer for Online Action Detection
