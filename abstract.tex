The ability to understand the surrounding scene is of paramount importance for Autonomous Vehicles (AVs).
This paper presents a system capable to work in a real time guaranteed response times and online fashion, giving an immediate response to the arise of anomalies surrounding the AV, exploiting only the videos captured by a dash-mounted camera.
Our architecture, called \emph{MOVAD}, relies on two main modules: a short-term memory to extract information related to the ongoing action, implemented by a Video Swin Transformer adapted to work in an online scenario, and a long-term memory module that considers also remote past information thanks to the use of a Long-Short Term Memory (LSTM) network.
We evaluated the performance of our method on Detection of Traffic Anomaly (DoTA) dataset, a challenging collection of dash-mounted camera videos of accidents.
After an extensive ablation study, MOVAD is able to reach an AUC score of 82.11\%, surpassing the current state-of-the-art by $+2.81\%$ AUC.
Our code will be available on {\footnotesize \url{https://github.com/IMPLabUniPr/movad/tree/icip}}