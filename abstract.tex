Autonomous Vehicles (AVs) are almost certainly becoming a reality for the near future thanks to the substantial recent advances in computer vision.
To make this happen, it is of paramount importance to give to AVs the ability to understand the surrounding scene.
This paper presents a system capable to work in a real-time and online fashion, giving an immediate response to the arise of anomalies surrounding the AV, exploiting only the videos captured by a dash-mounted camera.
Our architecture, called \emph{MOVAD}, relies on two main modules: a short-term memory to extract information related to the ongoing action, implemented by a Video Swin Transformer adapted to work in an online scenario, and a long-term memory module that considers also remote past information thanks to the use of a Long-Short Term Memory (LSTM) network.
We evaluated the performance of our method on Detection of Traffic Anomaly (DoTA) dataset, a challenging collection of dash-mounted camera videos of accidents.
After an extensive ablation study, MOVAD is able to reach an AUC score of 82.05\%, surpassing the current state-of-the-art by $+2.75\%$ AUC.
Our code will be available on \url{https://github.com/IMPLabUniPr/movad/tree/icip}