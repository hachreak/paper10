With the substantial recent advances in computer vision, Autonomous Vehicles (AVs) are almost certainly becoming a reality for the near future.
To make this happening, it is of paramount importance to give to AVs the ability to understand the surrounding scene.
%*Autonomous Vehicles (AVs) are becoming a reality for the near future.
%*Self-driving systems are being studied
%*Embedded systems need a way of understanding the hazardousness of surrounding scene
This paper presents a system capable of giving an immediate response to the arise of anomalies surrounding the AV exploiting only the videos captured by a dash-mounted camera.
For such task we propose \emph{MOVAD}, an architecture set to work in a real-time and online fashion that is composed by two modules: a short-term memory composed by a Video Swin Trasformer (VST) adapted to work in a real-time scenario and a long-term memory module that considers remote past information thanks to the use of a Long-Short Term Memory (LSTM).
We evaluated the performance of our method on Detection of Traffic Anomaly (DoTA) dataset, a challenging collection of dash-mounted camera videos of accidents.
After an extensive ablation study, we were able of reaching an AUC score of \anote{xx} surpassing the current state-of-the-art.
Our code will be available on Github prior to final submission.