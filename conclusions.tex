\section{Conclusions}
\label{sec:conclusions}

In this paper, we proposed a new architecture called MOVAD for the online VAD task.
Our model introduces two new modules: a short-term memory to extract information related to the ongoing action, implemented by a Video Swin Transformer adapted to work in a online scenario, and a long-term memory module that considers remote past information thanks to the use of a LSTM.
We evaluated the performance of our method on Detection of Traffic Anomaly (DoTA) dataset, a collection of dash-mounted camera videos of accidents, and we reach an AUC score of 82.11\%, surpassing the current state of the art by $2.81\%$ AUC.