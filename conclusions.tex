\section{Conclusion}
\label{sec:conclusions}

In this paper, we proposed a new architecture called MOVAD for (online and frame-level) video anomaly detection.
Our model is composed by two modules: a short-term memory to extract information related to the ongoing action, implemented by a Video Swin Transformer adapted to work in a online scenario, and a long-term memory module that considers remote past information thanks to the use of a Long-Short Term Memory (LSTM).
We evaluated the performance of our method on Detection of Traffic Anomaly (DoTA) dataset, a challenging collection of dash-mounted camera videos of accidents, and we reach an AUC score of \anote{81.70}, surpassing the current state-of-the-art by $+2.4$ AUC.